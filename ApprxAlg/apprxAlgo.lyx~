#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "cmss" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family sfdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Summary
\end_layout

\begin_layout Enumerate
Motivation related to NPC
\end_layout

\begin_layout Enumerate
Vertex cover
\end_layout

\begin_deeper
\begin_layout Enumerate
Running time
\end_layout

\begin_layout Enumerate
Correctness
\end_layout

\begin_layout Enumerate
Approximation ratio
\end_layout

\end_deeper
\begin_layout Enumerate
Randomized approximation algorithms
\end_layout

\begin_deeper
\begin_layout Enumerate
Max-3CNF-SAT introduction
\end_layout

\begin_layout Enumerate
Expected approximation ratio
\end_layout

\end_deeper
\begin_layout Standard
Example vertex cover
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Vertex-cover
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Vertex cover
\end_layout

\begin_layout Standard
The algorithm works by maintaining a set of 
\begin_inset Formula $C$
\end_inset

 vertices cover the graph.
 While 
\begin_inset Formula $E$
\end_inset

 is not empty, we pick an arbitrary edge from 
\begin_inset Formula $(u,v)\in E$
\end_inset

 and the endpoints to 
\begin_inset Formula $C=\{u,v\{\cup C$
\end_inset

 and then remove all edges that have endpoints in 
\begin_inset Formula $u$
\end_inset

 or 
\begin_inset Formula $v$
\end_inset

.
 
\series bold

\begin_inset Newline newline
\end_inset

Theorem: 35.1
\end_layout

\begin_layout Standard
APPROX-VERTEX-COVER is a polynomial-time 2-approximation algorithm.
 
\series bold

\begin_inset Newline newline
\end_inset

Proof:
\end_layout

\begin_layout Standard
We can use an adjacency list to represent the edges 
\begin_inset Formula $E$
\end_inset

.
 Now in constant time we pick an edge from the list, and look at the end-points
 
\begin_inset Formula $(u,v)$
\end_inset

.
 Now we need to remove the edges incident on 
\begin_inset Formula $u,v$
\end_inset

.
 Since we can at most pick and remove 
\begin_inset Formula $E$
\end_inset

 edges we get some running time related to 
\begin_inset Formula $E$
\end_inset

.
 Additionally, we look at the end-points, so we can at most look at all
 vertices giving us total 
\begin_inset Formula $O(V+E)$
\end_inset

 running time.
 
\emph on
Note an adjacency list is just a list of tuples, where the first index is
 a vertex 
\begin_inset Formula $u$
\end_inset

, and the next is the list of vertices that is adjacent to 
\begin_inset Formula $u$
\end_inset

.
\end_layout

\begin_layout Standard
We get a vertex cover since we loop over edges in 
\begin_inset Formula $(u,v)\in G.E$
\end_inset

 and add the endpoints to 
\begin_inset Formula $C\cup\{u,v\}$
\end_inset

.
 Meaning the edge is covered.
 Then we remove from 
\begin_inset Formula $E'$
\end_inset

 all edges incident on 
\begin_inset Formula $u,v$
\end_inset

, so we cover also these edges.
 And thereby we loop until all edges in 
\begin_inset Formula $E$
\end_inset

 are covered.
\end_layout

\begin_layout Standard
We let 
\begin_inset Formula $A$
\end_inset

 bet the set of edges arbitrarily picked at each iteration.
 Now we will look at the vertex cover to cover 
\begin_inset Formula $A$
\end_inset

.
 We know that an optimal cover for 
\begin_inset Formula $A$
\end_inset

 must include at least one endpoint for each edge in 
\begin_inset Formula $A$
\end_inset

.
 After the algorithm picked 
\begin_inset Formula $(u,v)\in E'$
\end_inset

, we remove from 
\begin_inset Formula $E'$
\end_inset

 all edges incident on either 
\begin_inset Formula $u,v$
\end_inset

(the endpoints).
 This means there are not two edges in 
\begin_inset Formula $A$
\end_inset

 that share an end-point (we made sure of this by removing all incident
 edges on 
\begin_inset Formula $u,v$
\end_inset

 that otherwise would have made this possible).
 Therefore, we must have the cover is at least as large as the number of
 edges
\begin_inset Formula 
\[
|C^{*}|\ge|A|
\]

\end_inset


\end_layout

\begin_layout Standard
We always pick an edge 
\begin_inset Formula $(u,v)\in E'$
\end_inset

 for which we know the endpoints 
\begin_inset Formula $u,v$
\end_inset

 are not already in 
\begin_inset Formula $C$
\end_inset

.
 This is ensured by the fact that each time we pick an edge 
\begin_inset Formula $(i,j)\in E'$
\end_inset

 we delete from 
\begin_inset Formula $E'$
\end_inset

 all edges incident on either 
\begin_inset Formula $i$
\end_inset

 or 
\begin_inset Formula $j$
\end_inset

 and add 
\begin_inset Formula $C=\{i,j\}\cup C$
\end_inset

.
 Since we pick 
\begin_inset Formula $|A|$
\end_inset

 edges in total, and we for each edge add two vertices, we get
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
C=2|A|
\]

\end_inset


\end_layout

\begin_layout Standard
we can combine the two bounds
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
C=2|A|\leq2|C^{*}|
\]

\end_inset


\end_layout

\begin_layout Standard
and we therefore get the solution is polynomial in time and at most twice
 as large as the optimal set.
 thus is is polynomial-time 2-approximate.
\end_layout

\begin_layout Section
Traveling-salesman
\end_layout

\begin_layout Enumerate
Preorder tree walk - current node, recursively left subtree, recursively
 right subtree
\end_layout

\begin_layout Enumerate
Minimum spanning tree - subset of edges with minimum edges that connects
 all vertices
\end_layout

\begin_layout Enumerate
\begin_inset Formula $c$
\end_inset

 is a cost function associated with each edge for which the triangle inequality
 holds
\end_layout

\begin_layout Standard

\series bold
Running time of APPROX-TSP-TOUR
\end_layout

\begin_layout Standard
The preorder tree walk takes 
\begin_inset Formula $O(V)$
\end_inset

 time.
 Using prims algorithm with an adjacency matrix gives us 
\begin_inset Formula $O(V^{2})$
\end_inset

 time for the minimum-spanning tree.
 Making the running time 
\begin_inset Formula $O(V^{2})$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Theorem 35.2: APPROX-TSP-TOUR is a polynomial-time 2-approximation algorithm
 for the traveling-salesman problem with the triangle inequality.
\end_layout

\begin_layout Standard
We let 
\begin_inset Formula $H^{*}$
\end_inset

 denote the optimal tour.
 When we have a tour, we can delete any edge to obtain a spanning tree,
 since a tour reaches all vertices and removing an edge makes it acyclic
 - thus a spanning tree.
 Since the edge cost is non-negative, then removing an edge makes the overall
 cost of the spanning tree smaller than the tour, giving us the lower bound
\begin_inset Formula 
\[
c(T)\leq c(H^{*})
\]

\end_inset


\end_layout

\begin_layout Standard
A full walk of 
\begin_inset Formula $T$
\end_inset

 visits its node, then the left subtree, and the it visits the node again,
 and then the right subtree.
 Thereby, each node in a full walk will be counted twice.
 Let us call the full walk of the minimum spanning tre 
\begin_inset Formula $T$
\end_inset

 for the walk 
\begin_inset Formula $W$
\end_inset

.
 We now get that the walk has the cost
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
c(W)=2c(T)
\]

\end_inset


\end_layout

\begin_layout Standard
Since the full walk visits each vertex more than once it is not generally
 a tour
\begin_inset Note Note
status open

\begin_layout Plain Layout
why?
\end_layout

\end_inset

.
 However, since the algorithm assumes that the triangle inequality for 
\begin_inset Formula $c$
\end_inset

 holds, then deleting any vertex from the walk 
\begin_inset Formula $W$
\end_inset

 does not increase the cost of the walk.
 That is, if we on the walk visit 
\begin_inset Formula $u,v,w$
\end_inset

 then we know 
\begin_inset Formula $c(u,w)\leq c(u,v)+c(v,w)$
\end_inset

.
 Thereby we can remove all but the first vertex visited by the full walk.
 Since we know only counts each vertex once, then this is the same as a
 preorder tree walk of 
\begin_inset Formula $T$
\end_inset

(the only difference from the full walk was that we counted the node again
 after visiting the left subtree).
 We let 
\begin_inset Formula $H$
\end_inset

 be the preorder walk.
 Since the tree order came from a minimum spanning tree, it is a hamiltonian
 cycle if we connect the last vertex of the walk with the root vertex.
 Furthermore, since 
\begin_inset Formula $H$
\end_inset

 was obtained by removing edges from 
\begin_inset Formula $W$
\end_inset

 then we know the cost
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
c(H)\leq c(W)
\]

\end_inset


\end_layout

\begin_layout Standard
combining this gives us
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
c(H)\leq c(W)=2c(t)\leq2c(H^{*})
\]

\end_inset


\end_layout

\begin_layout Standard
so we get the upper bound 
\begin_inset Formula $c(H)\leq2c(H^{*})$
\end_inset

, and the algorithm is polynomial in running time and at most twice as slow
 as an optimal solution.
\end_layout

\begin_layout Section
Set covering problem
\end_layout

\begin_layout Standard
In the ser-cover problem we are given the instance 
\begin_inset Formula $(X,F)$
\end_inset

.
 We have that 
\begin_inset Formula $X$
\end_inset

 is a finite set and 
\begin_inset Formula $F$
\end_inset

 is a family of subsets of 
\begin_inset Formula $X$
\end_inset

.
 We wish to find the minimal subset 
\begin_inset Formula $C\subseteq F$
\end_inset

 such that the entire subset covers 
\begin_inset Formula $X$
\end_inset

.
 That is we wish to find
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X=\bigcup_{s\in C}S
\]

\end_inset


\end_layout

\begin_layout Standard
The greedy algorithm will keep adding the subset to 
\begin_inset Formula $S$
\end_inset

 to 
\begin_inset Formula $C$
\end_inset

 that covers the most remaining elements.
 The number of iterations is bounded by 
\begin_inset Formula $\min(|X|,|F|)$
\end_inset

, since we can at most select 
\begin_inset Formula $|F|$
\end_inset

 subsets or there are more subsets than elements, in which we run for at
 most 
\begin_inset Formula $|X|$
\end_inset

 iterations.
 Each iterations selects 
\begin_inset Formula $S$
\end_inset

 that covers the most remaining elements.
 This means we will run for 
\begin_inset Note Note
status open

\begin_layout Plain Layout
why running time here
\end_layout

\end_inset

.
 Making the total running time
\begin_inset Formula 
\[
O(|X|\cdot|F|\cdot\min(|X|,|F|))
\]

\end_inset


\end_layout

\begin_layout Standard

\series bold
Theorem 35.4: GREEDY-SET-COVER is a polynomial-time p(n)-approximation algorithm,
 where 
\begin_inset Formula $p(n)=H(\max(\{|S|:S\in F\})$
\end_inset


\end_layout

\begin_layout Standard

\series bold
Proof
\end_layout

\begin_layout Standard
We analyze the running time by assigning a cost of 
\begin_inset Formula $1$
\end_inset

 to the set 
\begin_inset Formula $S_{i}$
\end_inset

 chosen and added to 
\begin_inset Formula $C=C\cup S_{i}$
\end_inset

 at the 
\begin_inset Formula $i$
\end_inset

'th iteration of the algorithm.
 The cost of 
\begin_inset Formula $1$
\end_inset

 is then evenly distributed among the elements covered for the first time
 by 
\begin_inset Formula $S_{i}$
\end_inset

(here it is meant that the first time an element is covered by a set 
\begin_inset Formula $S_{i}$
\end_inset

 then the each element covered for the first time will evenly distributed
 the cost of 1).
 We then let 
\begin_inset Formula $c_{x}$
\end_inset

 denote the cost assigned to element 
\begin_inset Formula $x\in X$
\end_inset

 that is covered for the first time.
 So the first time 
\begin_inset Formula $x$
\end_inset

 is covered, it assigned a fraction of 
\begin_inset Formula $1$
\end_inset

 this fraction is denoted by 
\begin_inset Formula $c_{x}$
\end_inset

.
 Furthermore, since this fraction is only assigned once - the first time
 
\begin_inset Formula $x$
\end_inset

 is covered - then we get this fraction to be
\begin_inset Formula 
\[
c_{x}=\frac{1}{|S_{i}-(S_{1}\cup,...,\cup S_{i-1})|}
\]

\end_inset


\end_layout

\begin_layout Standard
that is, when 
\begin_inset Formula $x$
\end_inset

 is covered for the first time, then the elements that are also covered
 for the first time are those in set 
\begin_inset Formula $S_{i}$
\end_inset

 minus those that might have already been covered before by previous subsets.
 Since we know that the algorithm assigns 1 unit of cost at each iteration
 (each time we select a subset), we get the sum
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
|C|=\sum_{x\in X}c_{x}
\]

\end_inset


\end_layout

\begin_layout Standard
since the sum of 
\begin_inset Formula $c_{x}$
\end_inset

 of the elements covered the first time by 
\begin_inset Formula $S_{i}$
\end_inset

 is 1, so adding all these points gives total number of sets added.
 We know that each 
\begin_inset Formula $x\in X$
\end_inset

 must be in at least one cover in the optimal solution 
\begin_inset Formula $C^{*}$
\end_inset

(possibly more covers in case of overlapping covers) and this gives us
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
|C^{*}|=\sum_{S\in C^{*}}\sum_{x\in S}c_{x}\ge\sum_{x\in X}c_{x}=|C|
\]

\end_inset


\end_layout

\begin_layout Standard
To be clear, we get the inequality since the subsets 
\begin_inset Formula $S\in C^{*}$
\end_inset

 might contain overlapping elements, so we might add 
\begin_inset Formula $c_{x}$
\end_inset

 multiple times for each 
\begin_inset Formula $x\in X$
\end_inset

.
 This therefore gives us
\begin_inset Formula 
\[
|C|\leq\sum_{S\in C^{*}}\sum_{x\in S}c_{x}
\]

\end_inset

Then it can be proven that
\begin_inset Formula 
\[
\sum_{x\in X}c_{x}\leq H(|S|)
\]

\end_inset

 that is the sum is less than the 
\begin_inset Formula $|S|$
\end_inset

-harmonic number for any set 
\begin_inset Formula $S\in F.$
\end_inset

 Using this and the bound on 
\begin_inset Formula $|C|$
\end_inset

 gives the upper bound
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
|C|\leq\sum_{s\in C^{*}}H(|S|)\leq|C^{*}|\cdot H(\max(\{|S|:s\in F\})
\]

\end_inset


\end_layout

\begin_layout Standard
where the second inequality holds since if we take the largest set, it gives
 the largest harmonic number, and we simply add it 
\begin_inset Formula $|C^{*}|$
\end_inset

 times.
 Therefore we must now show the bounder with the harmonic number.
 Let us consider any set 
\begin_inset Formula $S\in F$
\end_inset

 and any 
\begin_inset Formula $i=1,2,...,|C|$
\end_inset

.
 We the let 
\begin_inset Formula 
\[
u_{i}=|S-(S_{1}\cup S_{2}\cup...\cup S_{i})|
\]

\end_inset

 be the number of elements that are initially uncovered in 
\begin_inset Formula $S$
\end_inset

 after having selected 
\begin_inset Formula $i$
\end_inset

 subsets (remember we chose the set 
\begin_inset Formula $S$
\end_inset

 arbitrarily).
 Now we let 
\begin_inset Formula $k$
\end_inset

 be the least index for which we get the 
\begin_inset Formula $u_{k}=0$
\end_inset

.
 Meaning, at index 
\begin_inset Formula $k$
\end_inset

 every element of 
\begin_inset Formula $S$
\end_inset

 has been covered by at least one of the subsets 
\begin_inset Formula $S_{1}...S_{k}$
\end_inset

.
 Since we pick the least 
\begin_inset Formula $k$
\end_inset

 with this property, we still have that 
\begin_inset Formula $u_{k-1}=|S_{1}\cup S_{2}\cup...\cup S_{k-1}|>0$
\end_inset

 and there are still uncovered elements in 
\begin_inset Formula $S$
\end_inset

.
 Since choosing a new subset covers at least as many elements of 
\begin_inset Formula $S$
\end_inset

 we get that
\begin_inset Formula $u_{i-1}\ge u_{i}$
\end_inset

 and.
 We will also have that 
\begin_inset Formula $u_{i-1}-u_{i}$
\end_inset

 elements are covered for the first time when selecting set 
\begin_inset Formula $S_{i}$
\end_inset

 for 
\begin_inset Formula $i=1,2,...,k$
\end_inset

, since 
\begin_inset Formula $u_{i-1}$
\end_inset

 was the number of uncovered elements after selecting set 
\begin_inset Formula $S_{i-1}$
\end_inset

 and 
\begin_inset Formula $u_{i}$
\end_inset

 are the number of uncovered elements after selecting set 
\begin_inset Formula $S_{i}$
\end_inset

 so the difference must be the number of elements 
\begin_inset Formula $S_{i}$
\end_inset

 covered..
 We stop at 
\begin_inset Formula $k$
\end_inset

 since this is the time when all elements of 
\begin_inset Formula $S$
\end_inset

 are covered for the first time.
 Therefore, we get that the fraction assigned to each element 
\begin_inset Formula $x\in S$
\end_inset

 becomes
\begin_inset Formula 
\[
\sum_{x\in S}c_{x}=\sum_{i=1}^{k}(u_{i-1}-u_{i})\cdot\frac{1}{|S_{i}-(S_{1}\cup S_{2}\cup...\cup S_{i-1})|}
\]

\end_inset

since 
\begin_inset Formula $u_{i-1}-u_{i}$
\end_inset

 counts the number of elements covered for the first time when adding set
 
\begin_inset Formula $S_{i}$
\end_inset

, the denominator 
\begin_inset Formula $|S_{i}-(S_{1}\cup S_{2}\cup...\cup S_{i-1})|$
\end_inset

 also counts the number of elements covered by 
\begin_inset Formula $S_{i}$
\end_inset

, and each term of the sum is 
\begin_inset Formula $1$
\end_inset

, so this counts the total number of sets needed to cover 
\begin_inset Formula $S$
\end_inset

.
 However, that is also what 
\begin_inset Formula $\sum_{x\in S}c_{x}$
\end_inset

 does.
 Since our greedy choice ensures we at each iteration always pick the set
 that is largest then we know
\begin_inset Formula 
\[
|S_{i}-(S_{1}\cup S_{2}\cup...\cup S_{i-1})|\ge|S-(S_{1}\cup S_{2}\cup...\cup S_{i-1})|=u_{i-1}
\]

\end_inset

 since otherwise the algorithm would have chosen 
\begin_inset Formula $S$
\end_inset

(
\begin_inset Formula $S$
\end_inset

would have covered more elements than 
\begin_inset Formula $S_{i}$
\end_inset

).
 We can insert this to get a smaller denominator and thus an upper bound
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\sum_{x\in S}c_{x}\leq & \sum_{i=1}^{k}(u_{i-1}-u_{i})\cdot\frac{1}{u_{i-1}}\\
= & \sum_{i=1}^{k}\sum_{j=u_{i}+1}^{u_{i-1}}\frac{1}{u_{i-1}}\text{(since \ensuremath{(u_{i-1}-u_{i})} is the inner sum and sums are inclsv.)}\\
\leq & \sum_{i=1}^{k}\sum_{j=u_{i}+1}^{u_{i-1}}\frac{1}{j}\text{ (since \ensuremath{j\leq u_{i-1}}making the fraction larger)}\\
= & \sum_{i=1}^{k}\left(\sum_{j=1}^{u_{i-1}}\frac{1}{j}-\sum_{j=1}^{u_{i}}\frac{1}{j}\right)\text{(all wil cancel out until we get from before)}\\
= & \sum_{i=1}^{k}\left(H(u_{i-1})-H(u_{i})\right)\text{ by definition of harmonic number}\\
= & H(u_{0})-H(u_{k})\text{ by telescoping sum argument}\\
= & H(u_{0})-H(0)\text{ since we defined \ensuremath{H(0)=0}}\\
= & H(u_{0})\\
= & H(|S|)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
so now we have completed the proof.
\end_layout

\begin_layout Standard

\series bold
Corollary
\end_layout

\begin_layout Standard
There is a bound 
\begin_inset Formula $\sum_{k=1}^{n}\frac{1}{n}\le\ln n+1$
\end_inset

.
 Since we have shown that 
\begin_inset Formula 
\[
p(n)=H(\max\{|S|:S\in F\})=\sum_{k=1}^{\max\{|S|:S\in F\})}\frac{1}{k}
\]

\end_inset


\end_layout

\begin_layout Standard
then we can just upper bound this to
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(n)\leq H(|X|)=\sum_{k=1}^{|X|}\frac{1}{k}\leq\ln|X|+1
\]

\end_inset


\end_layout

\begin_layout Section
Randomization and linear programming
\end_layout

\begin_layout Standard
We say that a randomized algorithm has an approximation ratio 
\begin_inset Formula $p(n)$
\end_inset

 for some input size 
\begin_inset Formula $n$
\end_inset

.
 The expected cost 
\begin_inset Formula $C$
\end_inset

 of the solution produced by the algorithm is within a factor of 
\begin_inset Formula $p(n)$
\end_inset

 of the cost 
\begin_inset Formula $C^{*}$
\end_inset

 of an optimal solution.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\max\left(\frac{C}{C^{*}},\frac{C^{*}}{C}\right)\leq p(n)
\]

\end_inset


\end_layout

\begin_layout Standard
Randomized algorithms that have this ratio are called randomized 
\begin_inset Formula $p(n)$
\end_inset

-approximation algorithms.
 
\end_layout

\begin_layout Standard

\series bold
MAX-3-CNF satisfiability
\series default
 is the problem of finding a set of variables that for which the most clauses
 evaluate to 1.
 This is useful in case that not all clauses can evaluate to 1.
\end_layout

\begin_layout Subsection
MAX-3-CNF
\end_layout

\begin_layout Standard

\series bold
Theorem 35.6
\end_layout

\begin_layout Standard
Given an instance of MAX-3-CNF satisfiability with n variables 
\begin_inset Formula $x_{1},x_{2},...,x_{n}$
\end_inset

 and m clauses, the randomized algorithm that independently sets each variable
 to 1 with probability 1=2 and to 0 with probability 1=2 is a randomized
 8=7-approximation algorithm.
 
\emph on
Note we assume that a variable and its negation cannot appear in the same
 clause.
 
\end_layout

\begin_layout Standard

\series bold
Proof
\end_layout

\begin_layout Standard
We suppose that we have set each variable to 1 with probability 1/2 and
 to 0 with probability 1/2.
  There are 
\begin_inset Formula $m$
\end_inset

 clauses and we define an indicator variable 
\begin_inset Formula $Y_{i}$
\end_inset

 for 
\begin_inset Formula $i=1,2,...,m$
\end_inset

  to be
\begin_inset Formula 
\[
Y_{i}=[\text{clause }i\text{ is satisfied}]
\]

\end_inset


\end_layout

\begin_layout Standard
Since each variable is independently set, and there are only distinct literals
 in each clause with no variable and its negation, we know that the probability
 that no literals in a clause is 1 will be 
\begin_inset Formula $\left(\frac{1}{2}\right)^{3}=\frac{1}{8}$
\end_inset

(since the probability for each being 1 if 1/2 and they are set independently
 so we can multiply the probabilities for success).
 The probability that no literal in a clause evaluates to 1 is the same
 as the probability that clause evaluates to false (a 3-CNF clause is only
 0 if all its literals are 0, since it is 3 literals and their logical or).
 Therefore, the probability that a clause evaluates to 1 will be 
\begin_inset Formula $1-\frac{1}{8}=\frac{7}{8}$
\end_inset

.
 The expectation of 
\begin_inset Formula $Y_{i}$
\end_inset

 is therefore 
\begin_inset Formula $E[Y_{i}]=\frac{7}{8}$
\end_inset

 since the expectation of a bernouli random variable is the probability
 of success.
 Now we let the random variable 
\begin_inset Formula $Y$
\end_inset

 count the number of satisfied clauses.
 That is we have 
\begin_inset Formula $Y=\sum_{i=1}^{m}Y_{i}$
\end_inset

.
 Taking the expectation gives
\begin_inset Formula 
\begin{align*}
E[Y] & =E\left[\sum_{i=1}^{m}Y_{i}\right]\\
 & \sum_{i=1}^{m}E[Y_{i}]\\
 & \sum_{i=1}^{m}\frac{7}{8}\\
 & m\frac{7}{8}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
An upper bound on the maximum number of satisfied clauses is 
\begin_inset Formula $m$
\end_inset

.
 Therefore we get the approximation ratio
\begin_inset Formula 
\[
\frac{m}{(m\frac{7}{8})}=\frac{8}{7}
\]

\end_inset


\end_layout

\begin_layout Subsection
Approximating weighted vertex cover using linear programming
\end_layout

\begin_layout Standard
For this problem we are given an undirected graph 
\begin_inset Formula $G=(V,E)$
\end_inset

 where each vertex 
\begin_inset Formula $v\in V$
\end_inset

 has an associated weight 
\begin_inset Formula $w(v)$
\end_inset

.
 The weight of a vertex cover 
\begin_inset Formula $V'\subseteq V$
\end_inset

 is defined to be 
\begin_inset Formula $w(V')=\sum_{v\in V'}w(v)$
\end_inset

, and we wish to find a vertex cover of minimum weight.
 This is different from the normal vertex cover, so we cannot use that for
 finding the minimum cover (since it might give un-optimal solution).
 A randomized algorithm will also give an un-optimal solution.
\end_layout

\begin_layout Standard

\series bold
The 0-1 integer program
\series default
 is defined as follows: We associate a variable 
\begin_inset Formula $x(v)$
\end_inset

 with each vertex in 
\begin_inset Formula $V$
\end_inset

, and we require that 
\begin_inset Formula $x=\{0,1\}$
\end_inset

.
 Now we put 
\begin_inset Formula $v$
\end_inset

 into the cover 
\begin_inset Formula $C$
\end_inset

 if and only if 
\begin_inset Formula $x=1$
\end_inset

 (meaning if 
\begin_inset Formula $x$
\end_inset

 is in the cover it is also 1).
 This lets us constraint each edge 
\begin_inset Formula $(u,v)\in E$
\end_inset

 and we will have that 
\begin_inset Formula $x(v)+x(u)\geq1$
\end_inset

, since either 
\begin_inset Formula $x(v)$
\end_inset

or 
\begin_inset Formula $x(u)$
\end_inset

 or both will be 1 (We know that either 
\begin_inset Formula $u$
\end_inset

 or 
\begin_inset Formula $v$
\end_inset

 or both is in the cover, since otherwise not all vertices are covered,
 and if they are in the cover then 
\begin_inset Formula $x(v)$
\end_inset

 is 1, so the sum is at least 1).
 This gives the linear program 
\begin_inset Note Note
status open

\begin_layout Plain Layout
see the book
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The problem with the 
\series bold
0-1 integer problem 
\series default
is that when all 
\begin_inset Formula $w(v)=1$
\end_inset

 then this is equivalent to the original NP-hard vertex cover problem, and
 so solving this in polynomial time would mean P=NP.
 Therefore, we relax our assumption on 
\begin_inset Formula $x(v)$
\end_inset

 such that we only require 
\begin_inset Formula $0\leq x(v)\leq1$
\end_inset

.
 Then we get the following linear problem called 
\series bold
linear-programming relaxation
\series default

\begin_inset Note Note
status open

\begin_layout Plain Layout
see the book
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
We however have that any feasible solution to the 
\series bold
0-1 integer problem
\series default
 will also be a feasible to the 
\series bold
relaxation
\series default
 problem, and we can therefore use the 
\series bold
0-1 integer problem
\series default
 as a lower bound for the weight for an optimal solution.
 
\end_layout

\begin_layout Standard
The algorithm will work by initializing 
\begin_inset Formula $C=\emptyset$
\end_inset

 and the compute 
\begin_inset Formula $\bar{x}$
\end_inset

to be an optimal solution to the 
\series bold
relaxed problem
\series default
 and we then for each vertex 
\begin_inset Formula $v\in V$
\end_inset

 include it in 
\begin_inset Formula $C$
\end_inset

 if 
\begin_inset Formula $\bar{x}(v)\geq\frac{1}{2}$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Theorem
\series default
: Algorithm APPROX-MIN-WEIGHT-VC is a polynomial-time 2-approximation algorithm
 for the minimum-weight vertex-cover problem.
\end_layout

\begin_layout Standard

\series bold
Proof:
\end_layout

\begin_layout Standard
We first have to prove that the algorithm runs in polynomial time.
 We can solve a linear program in polynomial time, and thereafter we loop
 over all vertices and check whether they are in the solution to the linear
 program in which case we include the vertex 
\begin_inset Formula $v$
\end_inset

 in 
\begin_inset Formula $C$
\end_inset

.
 Therefore,  the algorithm runs in polynomial time.
 
\end_layout

\begin_layout Standard
Next we need to show the solution produced is 2-approximate.
 We let the set of vertices 
\begin_inset Formula $C^{*}$
\end_inset

 be an optimal solution to the minimum weight vertex cover (a vertex cover
 with minimum weight) and we let 
\begin_inset Formula $z^{*}$
\end_inset

be the value of an optimal solution to the 
\series bold
linear-relaxation problem
\series default
.
 That is 
\begin_inset Formula $z^{*}=\sum_{v\in V}w(v)x(v)$
\end_inset

 for an optimal solution to the linear program.
 
\begin_inset Formula $C^{*}$
\end_inset

 is an optimal vertex cover, and since it is a vertex cover it must therefore
 be 
\emph on
a feasible solution
\emph default
 to the linear program choosing 
\begin_inset Formula $x(v)=1$
\end_inset

 if 
\begin_inset Formula $v\in C^{*}$
\end_inset

 and 0 otherwise.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Be sure this is right
\end_layout

\end_inset

 However, it is only a feasible solution, we do not know whether it minimizes
 the linear program, and we thus have that 
\begin_inset Formula 
\[
z^{*}\leq w(C^{*})
\]

\end_inset

We still have to show the algorithm even produces a vertex cover.
 Therefore, we consider any edge 
\begin_inset Formula $(u,v)\in E$
\end_inset

.
 The 
\series bold
linear-programming-relaxation 
\series default
has the constraint that 
\begin_inset Formula $x(u)+x(v)\geq1,\forall(u,v)\in E$
\end_inset

 with part of the solution the variables 
\begin_inset Formula $\bar{x}$
\end_inset

.
 This must then imply that the solution to the linear program will have
 at least one of the variables 
\begin_inset Formula $\bar{x}(u)$
\end_inset

 or 
\begin_inset Formula $\bar{x}(v)$
\end_inset

 is at least 
\begin_inset Formula $1/2$
\end_inset

 since otherwise the constraint will not hold.
 Since we took any edge 
\begin_inset Formula $(u,v)$
\end_inset

 and we showed that at least one of 
\begin_inset Formula $u,v$
\end_inset

 will have weight greater than 
\begin_inset Formula $1/2$
\end_inset

, and the algorithm picks vertices 
\begin_inset Formula $v\in V$
\end_inset

 for which 
\begin_inset Formula $\bar{x}(v)\geq1/2$
\end_inset

, the set 
\begin_inset Formula $C$
\end_inset

 will be a cover.
\end_layout

\begin_layout Standard
We can bound the value of the optimal solution 
\begin_inset Formula $z^{*}$
\end_inset

 for the 
\series bold
relaxed
\series default
 linear program as
\begin_inset Formula 
\begin{align*}
z^{*}= & \sum_{v\in V}w(v)\bar{x}(v)\\
\geq & \sum_{\{v\in V:\bar{x}(v)\geq1/2\}}w(v)\bar{x}(v)\text{ (we sum over less)}\\
\geq & \sum_{\{v\in V:\bar{x}(v)\geq1/2\}}w(v)\frac{1}{2}\text{ (the variable is at least 1/2)}\\
= & \sum_{v\in C}w(v)\frac{1}{2}\text{ (how we construct c)}\\
= & \frac{1}{2}\sum_{v\in C}w(v)\\
 & \frac{1}{2}w(C)\\
\implies & 2\cdot z^{*}\geq w(C)
\end{align*}

\end_inset

 With an upper and lower bound on the optimal solution 
\begin_inset Formula $z^{*}$
\end_inset

 produced by the 
\series bold
relaxed
\series default
 linear program we get
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
w(C)\leq2\cdot z^{*} & \le2\cdot w(C^{*})\\
\implies & w(C)\leq w(C^{*})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
showing the algorithm indeed gives a 2-approximate solution.
\end_layout

\begin_layout Section
Subset-sum problem
\end_layout

\begin_layout Subsection
An exponential-time exact algorithm
\end_layout

\begin_layout Standard
We let 
\begin_inset Formula $P_{i}$
\end_inset

 denote the set of values created by selecting all subsets (including the
 empty subset) of 
\begin_inset Formula $\{x_{1}x_{2},...,x_{i}\}\subseteq S$
\end_inset

 and summing them together (
\begin_inset Formula $x_{1},x_{1}+x_{2},...,x_{1}+x_{i},...,$
\end_inset


\begin_inset Formula $x_{1}+x_{2}+,...,+x_{i})$
\end_inset

.
 We have the identify
\begin_inset Formula 
\[
P_{i}=P_{i-1}\cup(P_{i-1}+x_{i})
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $x_{i}$
\end_inset

 is the 
\begin_inset Formula $i$
\end_inset

'th element of 
\begin_inset Formula $S$
\end_inset

.
 This makes sense, since the subsets selected to create 
\begin_inset Formula $P_{i}$
\end_inset

 include all of those used to create 
\begin_inset Formula $P_{i-1}$
\end_inset

 and the set of all of those used to create 
\begin_inset Formula $P_{i-1}$
\end_inset

 and also selecting 
\begin_inset Formula $x_{i}$
\end_inset

 simultaneously.
 An exact exponential time algorithm is
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Verbatim

 n=|S|
\end_layout

\begin_layout Verbatim

L0 = <0>
\end_layout

\begin_layout Verbatim

for i = 1 to n
\end_layout

\begin_layout Verbatim

	Li = MERGE-LIST(Li-1, Li-1 + xi)
\end_layout

\begin_layout Verbatim

	remove from Li every element that is greater than t
\end_layout

\begin_layout Verbatim

return largest element of Ln
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Exact Exponential
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
This algorithm works since it iteratively builds the list 
\begin_inset Formula $L_{i}$
\end_inset

 to represent 
\begin_inset Formula $P_{i}$
\end_inset

, and therefore 
\begin_inset Formula $L_{i}$
\end_inset

 contains the sum of all subsets no larger than 
\begin_inset Formula $t$
\end_inset

, and will therefore find the larget sum of a subset that is no larger than
 t.
 It is exponential since 
\begin_inset Formula $L_{i}$
\end_inset

 can have length 
\begin_inset Formula $2^{i}$
\end_inset

, and thereby 
\begin_inset Formula $L_{n}$
\end_inset

can have length 
\begin_inset Formula $2^{n}$
\end_inset

 making it exponential time to scan for elements.
\end_layout

\begin_layout Subsection
A fully polynomial-time approximation scheme 
\end_layout

\begin_layout Standard
The problem with the exponential time algorithm is the size of each list
 
\begin_inset Formula $L_{i}$
\end_inset

.
 To make it faster, we will at each iteration trim 
\begin_inset Formula $L_{i}$
\end_inset

.
 We introduce a trimming parameter 
\begin_inset Formula $\delta$
\end_inset

 bounded by 
\begin_inset Formula $0<\delta<1$
\end_inset

.
 Trimming 
\begin_inset Formula $L$
\end_inset

 by 
\begin_inset Formula $\delta$
\end_inset

 means removing elements 
\begin_inset Formula $L$
\end_inset

 to create a new list 
\begin_inset Formula $L'$
\end_inset

, such that all elements removed, 
\begin_inset Formula $y$
\end_inset

, from 
\begin_inset Formula $L$
\end_inset

 are 
\emph on
approximated
\emph default
 by an element 
\begin_inset Formula $z$
\end_inset

 still in 
\begin_inset Formula $L'$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{y}{1+\delta}\le z\le y
\]

\end_inset


\end_layout

\begin_layout Standard
and 
\begin_inset Formula $z$
\end_inset

 is therefore an element in 
\begin_inset Formula $L'$
\end_inset

 that is at most 
\begin_inset Formula $y$
\end_inset

 and no smaller than 
\begin_inset Formula $\frac{1}{1+\delta}$
\end_inset

 than 
\begin_inset Formula $y$
\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Maybe do a trimming example.
\end_layout

\end_inset

.
 For instance, if we have 
\begin_inset Formula $L=[10,11,12]$
\end_inset

 and pick 
\begin_inset Formula $\delta=0.1$
\end_inset

, we get that 
\begin_inset Formula $\frac{11}{1+0.1}=10\leq10\leq11$
\end_inset

 and so we pick 
\begin_inset Formula $z=10$
\end_inset

 to represent/approximate 
\begin_inset Formula $y$
\end_inset

 in 
\begin_inset Formula $L'$
\end_inset

.
 Key idea is to remove elements that are 
\begin_inset Quotes eld
\end_inset

close to each other
\begin_inset Quotes erd
\end_inset

 since we only try to get an approximate solution and not an exact solution.
\end_layout

\begin_layout Standard
The trim procedure takes a sorted list 
\begin_inset Formula $L=[y_{1},y_{2},...,y_{m,}]$
\end_inset

 of integer values and a 
\begin_inset Formula $\delta$
\end_inset

.
 The procedure then loops over 
\begin_inset Formula $L$
\end_inset

 and removes duplicates and elements that are not more than 
\begin_inset Formula $1+\delta$
\end_inset

 larger than the adjacent elements.
 
\end_layout

\begin_layout Standard
Now we can create the algorithm APPROX-SUBSET-SUM(
\begin_inset Formula $S,t,\epsilon$
\end_inset

).
 It is just like the previous algorithm except that it trims the list 
\begin_inset Formula $L_{i}=MERGE-LISTS(L_{i-1},l_{i-1}+x_{i})$
\end_inset

, and passes the trimming parameter 
\begin_inset Formula $\delta=\epsilon/2n$
\end_inset

 to the trim procedure.
\end_layout

\begin_layout Standard

\series bold
Theorem 35.8
\end_layout

\begin_layout Standard
APPROX-SUBSET-SUM is a fully polynomial-time approximation scheme for the
 subset-sum problem.
\end_layout

\begin_layout Standard

\series bold
Proof
\end_layout

\begin_layout Standard
First we need to show that the algorithm does return a subset-sum of 
\begin_inset Formula $S$
\end_inset

.
 This can be shown by look at the property that every element of 
\begin_inset Formula $L_{i}$
\end_inset

 is in 
\begin_inset Formula $P_{i}$
\end_inset

.
 This is due to the fact that after merge, we get exactly the list representing
 
\begin_inset Formula $P_{i}$
\end_inset

, and trimming only removes elements.
 Likewise removing elements larger than 
\begin_inset Formula $t$
\end_inset

 also only removes elements.
 Since the value 
\begin_inset Formula $z^{*}$
\end_inset

 returned by the algorithm is the largest in 
\begin_inset Formula $L_{i}$
\end_inset

, and 
\begin_inset Formula $L_{i}$
\end_inset

 contains only elements in 
\begin_inset Formula $P_{i}$
\end_inset

, we know that 
\begin_inset Formula $z^{*}$
\end_inset

 is the value of some subset sum from 
\begin_inset Formula $S$
\end_inset

.
\end_layout

\begin_layout Standard
Next, we need to show that result is 
\begin_inset Formula $1+\epsilon$
\end_inset

-approximate.
 For every element 
\begin_inset Formula $y\in P_{i}$
\end_inset

 that is at most 
\begin_inset Formula $t$
\end_inset

 there exists an element 
\begin_inset Formula $z\in L_{i}$
\end_inset

(in the trimmed list) such that
\begin_inset Formula 
\[
\frac{y}{(1+\epsilon/2n)^{i}}\leq z\leq y
\]

\end_inset


\end_layout

\begin_layout Standard
This is proved in exercise 35.5-2.
 Since this holds for every elements in 
\begin_inset Formula $P_{i}$
\end_inset

, then it also holds for 
\begin_inset Formula $y^{*}\in P_{n}$
\end_inset

(the optimal solution to the subset sum).
 Therefore, when 
\begin_inset Formula $i=n$
\end_inset

, there exists an element 
\begin_inset Formula $z\in L_{n}$
\end_inset

 such that 
\begin_inset Formula 
\[
\frac{y^{*}}{(1+\epsilon/2n)^{n}}\leq z\leq y^{*}
\]

\end_inset


\end_layout

\begin_layout Standard
flipping the fractions (and thereby flipping the inequality) and multiplying
 by 
\begin_inset Formula $y^{*}$
\end_inset

 gives
\begin_inset Formula 
\begin{align*}
\left(1+\frac{\epsilon}{2n}\right)^{n} & \ge\frac{y^{*}}{z}\\
\frac{y^{*}}{z} & \leq\left(1+\frac{\epsilon}{2n}\right)^{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Since this holds for som 
\begin_inset Formula $z$
\end_inset

 then it must in particularely hold for 
\begin_inset Formula $z^{*}$
\end_inset

 since this is the largest 
\begin_inset Formula $z$
\end_inset

 and it thereby makes the fraction smaller so the inequality still holds
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{y^{*}}{z^{*}}\leq\left(1+\frac{\epsilon}{2n}\right)^{n}
\]

\end_inset


\end_layout

\begin_layout Standard
If we show that 
\begin_inset Formula $\left(1+\frac{\epsilon}{2n}\right)^{n}\leq1+\epsilon$
\end_inset

 then we have shown that 
\begin_inset Formula $\frac{y^{*}}{z^{*}}\leq1+\epsilon$
\end_inset

 and thereby that it is 
\begin_inset Formula $1+\epsilon$
\end_inset

 approximate.
 Taking the limit at infinity we get 
\begin_inset Formula $\lim_{n\rightarrow\infty}\left(1+\frac{\epsilon}{2n}\right)^{n}=e^{\epsilon/2}$
\end_inset

 by equation 3.14 (appendix in book).
 Then by exercise 35.5-3 we also have that 
\begin_inset Formula 
\[
\frac{d}{dx}\left(1+\frac{\epsilon}{2n}\right)^{n}>0
\]

\end_inset


\end_layout

\begin_layout Standard
This means that 
\begin_inset Formula $\left(1+\frac{\epsilon}{2n}\right)^{n}$
\end_inset

increases with 
\begin_inset Formula $n$
\end_inset

 as the limit of 
\begin_inset Formula $n$
\end_inset

 goes to infinity.
 Since the function reaches a limit of 
\begin_inset Formula $e^{\epsilon/2}$
\end_inset

 and it increases with 
\begin_inset Formula $n$
\end_inset

 then we must have
\begin_inset Formula 
\begin{align*}
\left(1+\frac{\epsilon}{2n}\right)^{n} & \leq e^{\epsilon/2}\\
 & \leq1+\epsilon/2+(\epsilon/2)^{2}\\
 & 1+\epsilon
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
showing the algorithm is 
\begin_inset Formula $1+\epsilon$
\end_inset

-approximate.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: rest of proof
\end_layout

\end_inset


\end_layout

\end_body
\end_document
